<!DOCTYPE html>
<html lang="en">
<head>
  <title>AI Assistant</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://unpkg.com/livekit-client@2.9.9/dist/livekit-client.umd.js"></script>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    #mediaElement {
      object-position: center 90%;
      transform: translateY(10%) scale(1.2);
    }
    
    @media (min-width: 768px) {
      #mediaElement {
        object-position: center 90%;
        transform: translateY(10%) scale(1.2);
      }
    }
    
    /* Connecting animation styles */
    .connecting-container {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      background-color: rgba(0, 0, 0, 0.7);
      color: white;
      z-index: 10;
    }
    
    .connecting-text {
      font-size: 1.5rem;
      margin-bottom: 1rem;
    }
    
    .loading-spinner {
      width: 50px;
      height: 50px;
      border: 5px solid rgba(255, 255, 255, 0.3);
      border-radius: 50%;
      border-top-color: #fff;
      animation: spin 1s ease-in-out infinite;
    }
    
    @keyframes spin {
      to { transform: rotate(360deg); }
    }
  </style>
</head>
<body class="bg-gray-100 p-3 font-sans">
  <div class="max-w-3xl mx-auto bg-white p-4 rounded-lg shadow-md">
    <div class="flex flex-col gap-3 mb-4">
      <img 
        src="logo.png" 
        alt="Ð›Ð¾Ð³Ð¾Ñ‚Ð¸Ð¿" 
        class="w-[85%] h-auto mx-auto"
      >
    </div>
    <div class="relative overflow-hidden rounded-lg border my-4 bg-gray-100" style="padding-top: 56.25%">
      <video id="mediaElement" 
             class="absolute top-0 left-0 w-full h-full object-cover" 
             autoplay></video>
      <!-- Connecting overlay -->
      <div id="connectingOverlay" class="connecting-container">
        <div class="connecting-text">Connecting...</div>
        <div class="loading-spinner"></div>
      </div>
    </div>
    <div class="flex flex-col gap-3 mb-4">      
      <div class="flex flex-col gap-2">
        <input id="taskInput" type="text" placeholder="Enter text to speak" 
               class="w-full p-2 border border-gray-300 rounded-md" disabled />
        <div class="flex gap-2">
          <button id="talkBtn" class="flex-1 px-4 py-2 bg-green-500 text-white rounded-md hover:bg-green-600 disabled:opacity-50" disabled>Talk</button>
          <button id="voiceBtn" class="px-4 py-2 bg-blue-500 text-white rounded-md hover:bg-blue-600 disabled:opacity-50" disabled>ðŸŽ¤ Voice</button>
        </div>
      </div>
    </div>
  </div>

  <script>
    if (!navigator.mediaDevices || !window.MediaStream) {
      updateStatus("WebRTC not supported in this browser");
    }
    
    const API_CONFIG = {
      apiKey: "MDQ1ZDgwYzgzNDc1NDRhZjgyYjVlOWI0OWRmYWQ0NGMtMTc0MzEyODU1NA==",
      serverUrl: "https://api.heygen.com",
    };
    const ASSEMBLY_API_KEY = "61bdee1fb59a40359276dfa83b8cb1aa";

    let sessionToken, sessionInfo, room, webSocket, mediaStream;
    let audioContext, analyser, mediaRecorder, isVoiceOn = false, recording = false, audioChunks = [], silenceCounter = 0;

    const talkBtn = document.getElementById("talkBtn");
    const voiceBtn = document.getElementById("voiceBtn");
    const taskInput = document.getElementById("taskInput");
    const mediaElement = document.getElementById("mediaElement");
    const connectingOverlay = document.getElementById("connectingOverlay");

    const updateStatus = msg => {
      console.log(`[${new Date().toLocaleTimeString()}] ${msg}`);
    };

    const enableControls = (state) => {
      taskInput.disabled = !state;
      talkBtn.disabled = !state;
      voiceBtn.disabled = !state;
    };

    const showConnecting = (show) => {
      connectingOverlay.style.display = show ? 'flex' : 'none';
    };

    const getSessionToken = async () => {
      const res = await fetch(`${API_CONFIG.serverUrl}/v1/streaming.create_token`, {
        method: "POST",
        headers: { "Content-Type": "application/json", "X-Api-Key": API_CONFIG.apiKey },
      });
      sessionToken = (await res.json()).data.token;
      updateStatus("Session token obtained");
    };

    const connectWebSocket = async (sessionId) => {
      const wsUrl = `wss://${new URL(API_CONFIG.serverUrl).hostname}/v1/ws/streaming.chat?session_id=${sessionId}&session_token=${sessionToken}&opening_text=Hello, I'm the virtual CEO of Vostok VR, an award-winning emerging tech agency in Singapore. Feel free to ask about our current and past projects and experiences.`;
      webSocket = new WebSocket(wsUrl);
      webSocket.onmessage = (e) => console.log("WS:", JSON.parse(e.data));
    };

    const createSession = async () => {
      if (!sessionToken) await getSessionToken();
      const res = await fetch(`${API_CONFIG.serverUrl}/v1/streaming.new`, {
        method: "POST",
        headers: { "Content-Type": "application/json", Authorization: `Bearer ${sessionToken}` },
        body: JSON.stringify({ quality: "high", avatar_name: "b082df383db140ed9a1b0b5c2b193e26", knowledge_base_id: "73d3457499824891b2d75d61ff0f4c54", stt_language: "eng", voice: { rate: 1.0 }, version: "v2", video_encoding: "H264" })
      });
      sessionInfo = (await res.json()).data;
      
      showConnecting(true); // Show connecting indicator
      updateStatus("Creating session...");
    };

    const handleTrackSubscribed = (track) => {
      mediaStream.addTrack(track.mediaStreamTrack);
      
      if (mediaStream.getVideoTracks().length && mediaStream.getAudioTracks().length) {
        mediaElement.srcObject = mediaStream;
        
        const handlePlay = async () => {
          try {
            await mediaElement.play();

            const playButton = document.getElementById('manualPlayBtn');
            if (playButton) playButton.remove();
          } catch (e) {
            updateStatus(`Playback error: ${e}`);
            addManualPlayButton();
          }
        };

        const addManualPlayButton = () => {
          if (!document.getElementById('manualPlayBtn')) {
            const btn = document.createElement('button');
            btn.id = 'manualPlayBtn';
            btn.className = 'absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2 ' +
                             'px-4 py-2 bg-red-500 text-white rounded-lg shadow-lg hover:bg-red-600';
            btn.textContent = 'Click to Play';
            btn.onclick = handlePlay;
            
            mediaElement.parentElement.appendChild(btn);
          }
        };

        handlePlay().catch(e => {
          updateStatus(`Initial playback failed: ${e}`);
          addManualPlayButton();
        });
      }
    };

    const startStreaming = async () => {
      await fetch(`${API_CONFIG.serverUrl}/v1/streaming.start`, {
        method: "POST",
        headers: { "Content-Type": "application/json", Authorization: `Bearer ${sessionToken}` },
        body: JSON.stringify({ session_id: sessionInfo.session_id }),
      });
      
      mediaStream = new MediaStream();
      room = new LivekitClient.Room();
      room.on(LivekitClient.RoomEvent.TrackSubscribed, handleTrackSubscribed);
      
      await room.prepareConnection(sessionInfo.url, sessionInfo.access_token);
      await connectWebSocket(sessionInfo.session_id);
      await room.connect(sessionInfo.url, sessionInfo.access_token);
      
      enableControls(true);
	  showConnecting(false); // Hide connecting indicator when stream starts
      updateStatus("Streaming started");
      startVoiceAutomatically();
    };

    const sendText = async (text) => {
      if (!sessionInfo) return;
      await fetch(`${API_CONFIG.serverUrl}/v1/streaming.task`, {
        method: "POST",
        headers: { "Content-Type": "application/json", Authorization: `Bearer ${sessionToken}` },
        body: JSON.stringify({ session_id: sessionInfo.session_id, text, task_type: "talk" }),
      });
      updateStatus(`Sent: ${text}`);
    };

    const processAudio = async () => {
      const blob = new Blob(audioChunks, { type: 'audio/webm' });
      const upload = await fetch("https://api.assemblyai.com/v2/upload", {
        method: "POST", headers: { authorization: ASSEMBLY_API_KEY }, body: blob
      });
      const { upload_url } = await upload.json();
      const transcript = await fetch("https://api.assemblyai.com/v2/transcript", {
        method: "POST",
        headers: { authorization: ASSEMBLY_API_KEY, "content-type": "application/json" },
        body: JSON.stringify({ audio_url: upload_url })
      });
      const { id } = await transcript.json();
      const poll = async () => {
        const res = await fetch(`https://api.assemblyai.com/v2/transcript/${id}`, {
          headers: { authorization: ASSEMBLY_API_KEY }
        });
        const { status, text } = await res.json();
        if (status === "completed" && text) {
          taskInput.value = text;
          sendText(text);
        } else if (status !== "completed") {
          setTimeout(poll, 1000);
        }
      };
      poll();
    };

    const checkVolume = () => {
      const data = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(data);
      const vol = data.reduce((a, b) => a + b, 0) / data.length;

      if (isVoiceOn) {
        if (vol > 10) {
          silenceCounter = 0;
          if (!recording) {
            recording = true;
            audioChunks = [];
            mediaRecorder.start();
          }
        } else if (recording) {
          silenceCounter++;
          if (silenceCounter > 15) {
            recording = false;
            mediaRecorder.stop();
          }
        }
      }
      requestAnimationFrame(checkVolume);
    };

    const initVoice = async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioContext = new AudioContext();
      analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream);
      source.connect(analyser);
      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstop = processAudio;
      checkVolume();
    };

    let isSessionActive = false;

    const stopSession = async () => {
      if (!sessionInfo) return;
      try {
        await fetch(`${API_CONFIG.serverUrl}/v1/streaming.stop`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${sessionToken}` },
          body: JSON.stringify({ session_id: sessionInfo.session_id })
        });
        
        if (webSocket) webSocket.close();
        if (room) room.disconnect();
        if (mediaStream) {
          mediaStream.getTracks().forEach(track => track.stop());
          mediaElement.srcObject = null;
        }
        
        // Clean up elements
        const playButton = document.getElementById('manualPlayBtn');
        if (playButton) playButton.remove();
        
        // Reset state
        sessionInfo = null;
        sessionToken = null;
        webSocket = null;
        room = null;
        mediaStream = null;
        
        updateStatus("Session stopped");
        enableControls(false);
        showConnecting(false);
      } catch (e) {
        updateStatus(`Error stopping session: ${e}`);
      }
    };

    async function startSessionAutomatically() {
      if (!isSessionActive) {
        try {
          showConnecting(true);
          await createSession();
          await startStreaming();
          isSessionActive = true;
        } catch (e) {
          updateStatus(`Error starting session: ${e}`);
          isSessionActive = false;
          showConnecting(false);
        }
      } else {
        try {
          await stopSession();
          isSessionActive = false;
        } catch (e) {
          updateStatus(`Error stopping session: ${e}`);
        }
      }
    };
    
    startSessionAutomatically();

    talkBtn.onclick = () => {
      const text = taskInput.value.trim();
      if (text) sendText(text);
      taskInput.value = "";
    };

    async function startVoiceAutomatically() {
      if (!audioContext) await initVoice();
      isVoiceOn = !isVoiceOn;
      voiceBtn.textContent = isVoiceOn ? 'ðŸ”´ Listening...' : 'ðŸŽ¤ Voice';
    };

    window.addEventListener('beforeunload', () => {
      if (isSessionActive) stopSession();
    });
  </script>
</body>
</html>